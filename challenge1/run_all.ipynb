{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.augmentations.transforms import Flip\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dataset\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "\n",
    "class Classifier(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        \n",
    "        #self.resnet = torch.hub.load('pytorch/vision:v0.9.0', 'resnet50', pretrained=False,num_classes = 2)\n",
    "        self.resnet = EfficientNet.from_pretrained('efficientnet-b3',num_classes = 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # in lightning, forward defines the prediction/inference actions\n",
    "        x = self.resnet(x)\n",
    "        prob = F.softmax(x)\n",
    "        return x, prob\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x, y = batch\n",
    "        p, _ = self(x)\n",
    "        loss = F.cross_entropy(p, y.long())\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        x, y = batch\n",
    "        p, _ = self(x)\n",
    "        \n",
    "        loss = F.cross_entropy(p, y.long())\n",
    "        f1 = f1_loss(y,p.argmax(1))\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_f1',f1)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop.\n",
    "        # It is independent of forward\n",
    "        \n",
    "        x, y = batch\n",
    "        p, _ = self(x)\n",
    "        \n",
    "        loss = F.cross_entropy(p, y.long())\n",
    "        f1 = f1_loss(y,p.argmax(1))\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_f1',f1)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=3e-4)\n",
    "        return optimizer\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        train_ds = dataset.getTrainDs(self.args['train_tr'])\n",
    "        loader= DataLoader(train_ds,batch_size = self.args['batch_size'],num_workers = 6,shuffle=True)\n",
    "        return loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        val_ds = dataset.getValDs(self.args['val_tr'])\n",
    "        loader= DataLoader(val_ds,batch_size = self.args['batch_size'],num_workers = 6)\n",
    "        return loader\n",
    "    def test_dataloader(self):\n",
    "        val_ds = dataset.getValDs(self.args['val_tr'])\n",
    "        loader= DataLoader(val_ds,batch_size = self.args['batch_size'],num_workers = 6)\n",
    "        return loader\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        val_ds = dataset.getTestDs(self.args['val_tr'])\n",
    "        loader= DataLoader(val_ds,batch_size = self.args['batch_size'],num_workers = 6)\n",
    "        return loader\n",
    "    \n",
    "    \n",
    "def f1_loss(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n",
    "\n",
    "    assert y_true.ndim == 1\n",
    "    assert y_pred.ndim == 1 or y_pred.ndim == 2\n",
    "\n",
    "    if y_pred.ndim == 2:\n",
    "        y_pred = y_pred.argmax(dim=1)\n",
    "\n",
    "\n",
    "    tp = (y_true * y_pred).sum().to(torch.float32)\n",
    "    tn = ((1 - y_true) * (1 - y_pred)).sum().to(torch.float32)\n",
    "    fp = ((1 - y_true) * y_pred).sum().to(torch.float32)\n",
    "    fn = (y_true * (1 - y_pred)).sum().to(torch.float32)\n",
    "\n",
    "    epsilon = 1e-7\n",
    "\n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "\n",
    "    f1 = 2* (precision*recall) / (precision + recall + epsilon)\n",
    "    f1.requires_grad = is_training\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self,df,mode,transforms = None):\n",
    "        self.imageID = df['ImageID']\n",
    "        self.labels = df['label']\n",
    "        self.transforms = transforms\n",
    "        self.labelmap = {'perseverance':0,'curiosity':1}\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __getitem__(self,x):\n",
    "        path = self.imageID.iloc[x]\n",
    "        label = float(self.labelmap[self.labels.iloc[x]])\n",
    "        i = cv2.imread(f'data/{self.mode}/'+str(path)+'.jpg')\n",
    "        i = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            i = self.transforms(image = i)['image']\n",
    "            \n",
    "        i = torch.tensor(i) / 255.0\n",
    "        #.unsqueeze_(-1)\n",
    "        i = i.permute(2,0,1)\n",
    "        if self.mode != 'test':\n",
    "            return i, label\n",
    "        else:\n",
    "            return i\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageID)\n",
    "    \n",
    "def getTrainDs(train_tr = None):\n",
    "    train_df = pd.read_csv('data/train.csv')\n",
    "    return ImgDataset(train_df,'train',train_tr)\n",
    "\n",
    "def getValDs(val_tr):\n",
    "    val_df = pd.read_csv('data/val.csv')\n",
    "    return ImgDataset(val_df,'val',val_tr)\n",
    "\n",
    "def getTestDs(test_tr):\n",
    "    val_df = pd.read_csv('data/sample_submission.csv')\n",
    "    return ImgDataset(val_df,'test',test_tr)\n",
    "\n",
    "def writeSub(p):\n",
    "    test_df = pd.read_csv('data/sample_submission.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5219aac544641379544963806a4e8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-9872615ed450>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_f1': 0.08072998374700546, 'test_loss': 0.7056330442428589}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d84ee1ae0be4e87843ff01d215b704f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    trainer = Trainer(max_epochs = 6, gpus = 1, precision=16, amp_level='O1',deterministic=True)\n",
    "    \n",
    "    train_tr = A.Compose([\n",
    "        A.CenterCrop(200,200,always_apply=True),\n",
    "        Flip()\n",
    "    ])\n",
    "    \n",
    "    val_tr = A.Compose([\n",
    "        A.CenterCrop(200,200,always_apply=True)\n",
    "    ])\n",
    "    \n",
    "    model = Classifier({'lr':3e-4,'batch_size':64,'train_tr':train_tr,'val_tr':val_tr})\n",
    "    \n",
    "    trainer.fit(model)\n",
    "    trainer.test(model)\n",
    "    out = trainer.predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def writeSub(p):\n",
    "    labelmap = {0:'perseverance',1:'curiosity'}\n",
    "    test_df = pd.read_csv('D:/rover/ch1/data/sample_submission.csv')\n",
    "    output_list = p.int().tolist()\n",
    "    output_list = [labelmap[i] for i in output_list]\n",
    "    test_df['label'] = output_list\n",
    "    test_df.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.tensor([])\n",
    "\n",
    "for i in range(len(out)):\n",
    "    output = torch.cat((output,torch.tensor(out[i][1]).argmax(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeSub(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
